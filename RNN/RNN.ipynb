{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZOdEdKhFJFNCxPl84Ly4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leochartrand/IFT615/blob/main/RNN/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apprenons à un RNN à générer du Shakespeare!"
      ],
      "metadata": {
        "id": "ZQ-qvLzjb91R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Mary, and will, my lord, to weep in such a one were prettiest​*\n",
        "\n",
        "​*Yet now I was adopted heir​​*\n",
        "\n",
        "​*Of the world’s lamentable day​​*\n",
        "\n",
        "​*To watch the next way with his father with his face?*"
      ],
      "metadata": {
        "id": "H7mtn1PSTPdt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Commençons par importer nos librairies"
      ],
      "metadata": {
        "id": "wUVxZJfIeX3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "4ao0jxUWcAIP"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Téléchargeons maintenant le jeu de données. Ce dernier est un ensemble de 40,000 lignes de Shakespeare provenant d'une variété de ses oeuvres. Ce *dataset* a été assemblé par Andrej Karpathy: https://github.com/karpathy/char-rnn (BSD License)"
      ],
      "metadata": {
        "id": "pkoSL4Cjgcis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/leochartrand/IFT615/main/RNN/shakespeare.txt\n",
        "\n",
        "data = open(r'shakespeare.txt').read()"
      ],
      "metadata": {
        "id": "NMngZsn1cBSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jetons un coup d'oeil au dataset. On peut imprimer par exemple les 1000 premiers charactères:"
      ],
      "metadata": {
        "id": "FMv0RFL2hWLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[:1000])"
      ],
      "metadata": {
        "id": "6uRZGCohcDFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prétraitons le jeu de donner un peu plus. Commençons par créer une \"dictionnaire\" des charactères que l'on trouve dans le jeu de données:"
      ],
      "metadata": {
        "id": "OpxvqcGVnmJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char_dict = sorted(list(set(data)))\n",
        "vocab_size = len(char_dict)\n",
        "print(\"Le jeu de données est constitué de %d charactères uniques.\"%vocab_size)"
      ],
      "metadata": {
        "id": "qqT7YEcXAcrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est important que les charactères puissent être interprétés par notre modèle. Pour cela, on peut commencer par convertir chaque charactère en un indice, qui prend position dans l'intervalle [0, vocab_size[. On veut aussi pouvoir faire l'inverse et obtenir des charactères à nouveau à la sortie du modèle:"
      ],
      "metadata": {
        "id": "INzw-l-fDCAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour éviter de faire la conversion plusieurs fois et de répéter du code, on\n",
        "# peut créer des dictionnaires qui font un \"mapping\" entre les charactères et leur index\n",
        "char_to_index = {char:i for i,char in enumerate(char_dict)}\n",
        "index_to_char = {i:char for i,char in enumerate(char_dict)}\n",
        "\n",
        "# Créons une simple fonction qui permettra d'obtenir les charactères directement lors de la génération:\n",
        "def get_char(index):\n",
        "  return index_to_char[index]\n",
        "def get_index(char):\n",
        "  return char_to_index[char]\n",
        "\n",
        "# On peut déjà convertir notre jeu de données en une liste d'indices!\n",
        "data = list(data)\n",
        "for i, char in enumerate(data):\n",
        "    data[i] = get_index(char)"
      ],
      "metadata": {
        "id": "Qirpq91pDCbT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut maintenant créer notre modèle!"
      ],
      "metadata": {
        "id": "jDP5Q6n1AhBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Char_RNN(nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size, num_layers):\n",
        "    super(Char_RNN, self).__init__()\n",
        "    self.layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, input_size)\n",
        "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.dense = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input, hidden):\n",
        "    embedded = self.embedding(input)\n",
        "    output, hidden = self.rnn(embedded, hidden)\n",
        "    output = self.dense(output)\n",
        "    return output, hidden\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "        return torch.zeros(self.layers, batch_size, self.hidden_size)\n",
        "\n",
        "char_model = Char_RNN(vocab_size, vocab_size, 128, 3)"
      ],
      "metadata": {
        "id": "uSg5pHljcFkb"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On passe à l'entraînement..."
      ],
      "metadata": {
        "id": "WCHaJKHlUlrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définissons nos hyperparametres\n",
        "epochs = 5\n",
        "batch_size = 100\n",
        "sequence_length = 50\n",
        "learning_rate = 5e-4\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(char_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# On garde un historique de l'entraînement pour visualiser nos résultats\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "  total_batches = (len(data) - sequence_length) // (sequence_length * batch_size)\n",
        "  with tqdm(total=total_batches) as progress:\n",
        "   for _ in range(total_batches):\n",
        "      start_index = random.randint(0, 100)\n",
        "\n",
        "      if start_index + sequence_length * batch_size > len(data) - sequence_length:\n",
        "          continue\n",
        "\n",
        "      input_seq = torch.tensor([data[j:j+sequence_length] for j in range(start_index, start_index + sequence_length * batch_size, sequence_length)])\n",
        "      target_seq = torch.tensor([data[j+1:j+sequence_length+1] for j in range(start_index, start_index + sequence_length * batch_size, sequence_length)])\n",
        "\n",
        "\n",
        "      if input_seq.size(0) != batch_size:\n",
        "          continue\n",
        "\n",
        "      hidden = char_model.init_hidden(batch_size)\n",
        "      char_model.zero_grad()\n",
        "\n",
        "      output, hidden = char_model(input_seq, hidden)\n",
        "      loss = criterion(output.view(-1, vocab_size), target_seq.view(-1))\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      loss_history.append(loss.item())\n",
        "      progress.update(1)\n",
        "      progress.set_description(\"Loss: %.4f\"%loss.item())"
      ],
      "metadata": {
        "id": "paKNK5TAcKJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisons la courbe d'apprentissage:"
      ],
      "metadata": {
        "id": "nji4nHPzKCuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_history)\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss history')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jor1v86SAKi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essayons maintenant degénérer du Shakespeare!"
      ],
      "metadata": {
        "id": "U8H-B50aKl0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = \"Bob\"\n",
        "temperature = 0.9\n",
        "gen_length = 2000\n",
        "\n",
        "char_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _ in range(gen_length):\n",
        "    # On prépare les données et le modèle\n",
        "    input_tensor = torch.tensor([[get_index(c) for c in seed][-sequence_length:]], dtype=torch.long)\n",
        "    hidden = char_model.init_hidden(1)\n",
        "\n",
        "    # Forward pass\n",
        "    output, hidden = char_model(input_tensor, hidden)\n",
        "\n",
        "    # On sélectionne le charactère selon les probabilités (sous forme d'indice)\n",
        "    # Ici, une variable de température assure une certaine stochasticité\n",
        "    logits = output[0, -1, :] / temperature\n",
        "    # On normalise les probabilités avec un softmax\n",
        "    prob_dist = F.softmax(logits, dim=0)\n",
        "\n",
        "    # On échantillone ensuite un indice dans la distribution\n",
        "    top_char_index = torch.multinomial(prob_dist, 1).item()\n",
        "\n",
        "    # On reconvertit en charactère\n",
        "    predicted_char = get_char(top_char_index)\n",
        "    seed += predicted_char\n",
        "\n",
        "    # Print the new character\n",
        "    print(predicted_char, end='', flush=True)\n",
        ""
      ],
      "metadata": {
        "id": "myCWATricMun"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}