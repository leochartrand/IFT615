{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leochartrand/IFT615/blob/main/CNN/CNN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCdTejS5-OYw"
      },
      "source": [
        "*Cette démonstration est inspirée du cours \"CS50’s Introduction to Artificial Intelligence with Python\" donné à l'Université d'Harvard.*\n",
        "\n",
        "https://cs50.harvard.edu/ai/2024/\n",
        "\n",
        "https://creativecommons.org/licenses/by-nc-sa/4.0/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i5YbW8fjiRD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "from skimage.io import imshow\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut commencer par charger le jeux de données MNIST:"
      ],
      "metadata": {
        "id": "LC2_hFFuVM-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root = './', train = True,\n",
        "                                        transform = torchvision.transforms.ToTensor(),\n",
        "                                        download = True)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = True)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root = './', train = False,\n",
        "                                       transform = torchvision.transforms.ToTensor())\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)"
      ],
      "metadata": {
        "id": "mjCJokIgIpo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profitons en pour observer quelques exemples du jeux de données:"
      ],
      "metadata": {
        "id": "4lTpXTTeVT1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index, (ex_data, ex_labels) = next(enumerate(test_dataloader))\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(9):\n",
        "  plt.subplot(3,3,i+1)\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(ex_data[i][0], cmap='gray')\n",
        "  plt.title(\"Vérité terrain: %d\"%(ex_labels[i]))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2fj4giPeViN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut maintenant instancier notre modèles et définir ses paramètres! Voici ci dessous un exemple de réseau de neuronnes qui utilise une couche convolutive suivie d'une couche de pooling."
      ],
      "metadata": {
        "id": "TAcd5uR1XYSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "\n",
        "    # Couche convolutive. Apprend 32 filtres en utilisant un noyau 3x3\n",
        "    nn.Conv2d(1, 32, (3, 3)),\n",
        "\n",
        "    # Activation ReLU\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # Couche de max-pooling de taille 2x2\n",
        "    nn.MaxPool2d((2, 2)),\n",
        "\n",
        "    # On applatie les données\n",
        "    nn.Flatten(),\n",
        "\n",
        "    # Couche dense\n",
        "    nn.Linear(5408, 128),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    # Couche dense finale avec comme sortie les probabilitées pour les 10 chiffres\n",
        "    nn.Linear(128, 10),\n",
        ")"
      ],
      "metadata": {
        "id": "Q2uuTedIQjZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On instancie un optimiseur qui s'occupe de la descente de gradient\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# On instancie notre fonction de parte\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "33kLWRu1mvVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entraînons maintenant notre modèle!"
      ],
      "metadata": {
        "id": "KlFHblQqoazW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# On garde un historique de l'entraînement pour visualiser nos résultats\n",
        "loss_history = []\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print(\"Epoch %d/%d\"%(epoch+1, epochs))\n",
        "  progress = tqdm(train_dataloader)\n",
        "  for index, (data, labels) in enumerate(progress):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_history.append(loss.item())\n",
        "    progress.set_description(\"Loss: %.4f\"%loss.item())"
      ],
      "metadata": {
        "id": "58hXKPAOJm47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut visualiser l'apprentissage de notre modèle à l'aide de la librairie ***matplotlib***:"
      ],
      "metadata": {
        "id": "GetjAV9--3ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epochs*len(train_dataloader)), loss_history)\n",
        "plt.xlabel('Batches')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss history')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7gNQ9E1o02Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Évaluons maintenant la précision de notre modèle sur le jeu de données de test:"
      ],
      "metadata": {
        "id": "B_UoQpVE_Pni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for data, labels in test_dataloader:\n",
        "  output = model(data)\n",
        "  _, predictions = torch.max(output,1)\n",
        "  correct += (predictions == labels).sum()\n",
        "  total += labels.size(0)\n",
        "\n",
        "print('Précision du modèle: %.3f %%' %(100*correct/total))"
      ],
      "metadata": {
        "id": "RXEjWafLJo47"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}