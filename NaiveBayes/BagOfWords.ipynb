{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leochartrand/IFT615/blob/main/NaiveBayes/BagOfWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*Cette démonstration est tirée du cours \"CS50’s Introduction to Artificial Intelligence with Python\" donné à l'Université d'Harvard.*\n",
        "https://cs50.harvard.edu/ai/2024/\n",
        "https://creativecommons.org/licenses/by-nc-sa/4.0/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comme toujours, on commence par importer les librairies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour passer à la suite, il nous faut préparer une certaine fonction utilitaire. La suivante permet d'extraire tous les mots distincts d'un document (ligne) et retourne un *set* de ceux-ci. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_words(document):\n",
        "    return set(\n",
        "        word.lower() for word in nltk.word_tokenize(document)\n",
        "        if any(c.isalpha() for c in word)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut maintenant charger le jeu de données. Il s'agit de deux fichiers contenant des échantillions positifs et négatifs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for filename in [\"positives.txt\", \"negatives.txt\"]:\n",
        "    with open(filename) as f:\n",
        "        corpus.append([\n",
        "            extract_words(line)\n",
        "            for line in f.read().splitlines()\n",
        "        ])\n",
        "\n",
        "positives, negatives = corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Créons maintenant un *set* de tous les mots possibles qu'on peut retrouver dans nos échantillons:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "words = set()\n",
        "for document in positives:\n",
        "    words.update(document)\n",
        "for document in negatives:\n",
        "    words.update(document)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nous avons besoin de quelques autres fonctions utilitaires. La suivante permet d'associer les mots dans les échantillons à une étiquette, et assembler le tout dans une structure de données qui pourra être interprétée lors de l'apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_features(documents, words, label):\n",
        "    features = []\n",
        "    for document in documents:\n",
        "        features.append(({\n",
        "            word: (word in document)\n",
        "            for word in words\n",
        "        }, label))\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La fonction ci-dessous permet de faire appel à notre modèle entraîné pour classifier un mot (ou plusieurs) donné en entrée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify(classifier, document, words):\n",
        "    document_words = extract_words(document)\n",
        "    features = {\n",
        "        word: (word in document_words)\n",
        "        for word in words\n",
        "    }\n",
        "    return classifier.prob_classify(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utilisons maintenant la fonction `generate_features` pour associer des mots à une certaine étiquette. Dans ce cas-ci, les étiquettes sont \"Positive\" et \"Negative\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "training = []\n",
        "training.extend(generate_features(positives, words, \"Positive\"))\n",
        "training.extend(generate_features(negatives, words, \"Negative\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Procédons maintenant à l'entrainement. Ici, la librairie NLTK fournit un classifieur déjà codé qu'on peut utiliser pour interpréter la structure de données qu'on vient de générer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(training)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "L'entraînement terminé, essayons de donner un mot à notre classifieur pour voir le résultat:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KTqzsU1dC0ER"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive: 0.5529\n",
            "Negative: 0.4471\n"
          ]
        }
      ],
      "source": [
        "s = input(\"s: \")\n",
        "result = (classify(classifier, s, words))\n",
        "for key in result.samples():\n",
        "    print(f\"{key}: {result.prob(key):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On peut voir qu'en donnant un mot connu par le modèle, on obtient une certaine probabilité qui penche vers le positif ou négatif. Cependant, si un mot ne se trouve pas dans le jeu de données d'entraînement, le modèle est indécis!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM0AkAIkOb7AqjP2TLBDP16",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
